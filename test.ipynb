{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "rect1 = (10,10,100,100)\n",
    "rect2 = (20,20,110,110)\n",
    "\n",
    "def rect_or(a,b):\n",
    "    x = min(a[0],b[0])\n",
    "    y = min(a[1],b[1])\n",
    "    w = max(a[0]+a[2],b[0]+b[2])-x\n",
    "    h = max(a[1]+a[3],b[1]+b[3])-y\n",
    "    return (x,y,w,h)\n",
    "\n",
    "def rect_and(a,b):\n",
    "    x = max(a[0],b[0])\n",
    "    y = max(a[1],b[1])\n",
    "    w = min(a[0]+a[2],b[0]+b[2])-x\n",
    "    h = min(a[1]+a[3],b[1]+b[3])-y\n",
    "    if w<0 or h<0: return (0,0,0,0)\n",
    "    return (x,y,w,h)\n",
    "\n",
    "def rect_centor(r):\n",
    "    return (int((r[0]+r[2])//2), int((r[1]+r[3])//2))\n",
    "\n",
    "def vec2_sin_cos(v1,v2): #input:(10,2),(-4,8)\n",
    "    v1 = np.array(v1,dtype=np.int32)\n",
    "    v2 = np.array(v2,dtype=np.int32)\n",
    "    v = v2-v1\n",
    "    v22 = np.sum(v**2)\n",
    "    d = np.sqrt(v22)\n",
    "    if d<=0.001: return (0.0,0.0)\n",
    "    return (v[0]/d, v[1]/d)\n",
    "\n",
    "def rect_andDIVor(a,b):\n",
    "    aband = rect_and(a,b)\n",
    "    abor = rect_or(a,b)\n",
    "    sand = aband[2]*aband[3]\n",
    "    sor = abor[2]*abor[3]\n",
    "    if sor<=0.001: return 0.0\n",
    "    return sand/sor\n",
    "\n",
    "def get_seq2_features(seqs):#[[(1,2),(23,12)],[(22,11),(12,11)]]\n",
    "    if len(seqs)!=2:\n",
    "        print(\"err get_seq2_features: len(seqs)!=2\")\n",
    "        return\n",
    "    if len(seqs[0])<=0 or len(seqs[1])<=0:\n",
    "        print(\"err get_seq2_features: len(seq)<=0\")\n",
    "        return \n",
    "    r1 = cv2.boundingRect(seqs[0])\n",
    "    r2 = cv2.boundingRect(seqs[1])\n",
    "    c1 = rect_centor(r1)\n",
    "    c2 = rect_centor(r2)\n",
    "    if r1[2]<=0 or r1[3]<=0 or r2[2]<=2 or r2[3]<=0:\n",
    "        print(\"err get_seq2_features: width or height <=0\")\n",
    "        return    \n",
    "    f0 = r1[2]/(r1[2]+r2[2])\n",
    "    f1 = r1[3]/(r1[3]+r2[3])\n",
    "    f2,f3 = vec2_sin_cos(c1,c2)\n",
    "    f4 = rect_andDIVor(r1,r2)\n",
    "    return (f0,f1,f2,f3,f4)\n",
    "    \n",
    "\n",
    "\n",
    "r = np.array([[1,1]],dtype=np.int32)\n",
    "re = cv2.boundingRect(r)\n",
    "print(re)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst =[1,2,3,4,5,6]\n",
    "lst[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector<Point> contour;\n",
    "# contour.push_back(Point2f(0, 0));\n",
    "# contour.push_back(Point2f(10, 0));\n",
    "# contour.push_back(Point2f(10, 10));\n",
    "# contour.push_back(Point2f(5, 4));\n",
    "# double area0 = contourArea(contour);\n",
    "# vector<Point> approx;\n",
    "# approxPolyDP(contour, approx, 5, true);\n",
    "# double area1 = contourArea(approx);\n",
    "# cout << \"area0 =\" << area0 << endl <<\n",
    "#         \"area1 =\" << area1 << endl <<\n",
    "#         \"approx poly vertices\" << approx.size() << endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "link_csv = pd.read_csv('link_train.csv') #打开一个csv文档\n",
    "print(\"link_csv:\",link_csv)\n",
    "#print(\"shape:\",link_csv.head(2)) #显示前2行数据\n",
    "#link_csv2 = link_csv.append([10.1,10.2,10.3,10.4,10.5],ignore_index=False)\n",
    "#print(\"link_csv2:\",link_csv2)\n",
    "# link_csv.loc[link_csv.shape[0]] = [0.1,0.2,0.3,0.4,0.5]\n",
    "# link_csv.loc[link_csv.shape[0]] = [0.2,0.2,0.3,0.4,0.5]\n",
    "link_trains = np.array(link_csv[['hratio','wratio','sin','cos','andor']]) #读取前n-1列训练数据数据到numpy\n",
    "link_labels = np.array(link_csv['lb'],dtype=np.float32) #读取最后一列标签到numpy\n",
    "#link_trains = np.vstack((link_trains,[2,3,4,5,6]))  #numpy添加数据\n",
    "print(link_labels)\n",
    "print(np.sum(link_labels<0.5))\n",
    "\n",
    "link_numpy = np.concatenate((link_trains,link_labels.reshape(-1,1)),axis=1)  #连接训练数据和标签\n",
    "#link_pad = pd.DataFrame(link_numpy,columns=link_csv.columns,index=None)  #创建pandas数据帧\n",
    "#print(\"linkpad:\",link_pad)\n",
    "#link_pad.to_csv(\"link_train_sv.csv\",index=False)  #将数据帧保存到csv文件\n",
    "\n",
    "# print(link_trains)\n",
    "# print(link_labels)\n",
    "print(link_numpy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.arange(10000).reshape(100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {}\n",
    "def aa(x):\n",
    "    x['ok']=\"1111\"\n",
    "    #x =x + 1\n",
    "\n",
    "aa(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def point_in_rect(rect,pt): #(10,10,100,100)  (40,40) True\n",
    "    nprect = np.array([[rect[0],rect[1]], \n",
    "                       [rect[0]+rect[2],rect[1]],\n",
    "                       [rect[0]+rect[2],rect[1]+rect[3]],\n",
    "                       [rect[0],rect[1]+rect[3]]])\n",
    "    return cv2.pointPolygonTest(nprect,pt,False)\n",
    "\n",
    "print(point_in_rect((10,10,100,100),(118,108)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch as tf\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Example of target with class indices\n",
    "loss = nn.CrossEntropyLoss()\n",
    "input = tf.randn(3, 5, requires_grad=True)\n",
    "print(\"input:\",input)\n",
    "target = tf.empty(3, dtype=tf.long).random_(5)\n",
    "print(\"target:\",target)\n",
    "output = loss(input, target)\n",
    "output.backward()\n",
    "# Example of target with class probabilities\n",
    "input = tf.randn(3, 5, requires_grad=True)\n",
    "print(\"input2:\",input)\n",
    "target = tf.randn(3, 5).softmax(dim=1)\n",
    "print(\"target2:\",target)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "tr = np.array([[1,2,4],[2,3,5],[11,4,1],[1,21,2],[6,4,4],[1,6,5],[1,7,8]])\n",
    "\n",
    "lb = np.array([1,0,-1,1,-1,1,0])\n",
    "lbflag = np.argwhere(lb<0)\n",
    "print(\"lbflag:\",lbflag)\n",
    "tr = np.delete(tr,lbflag,axis=0)\n",
    "lb = np.delete(lb,lbflag)\n",
    "\n",
    "print(\"tr:\",tr)\n",
    "print(\"lb:\",lb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_merge(seq1,seq2):\n",
    "    seqs = []\n",
    "    seqs.append(seq1)\n",
    "    seqs.append(seq2)\n",
    "    print(seq1)\n",
    "    print(seq2)\n",
    "    print(seqs)\n",
    "    return seqs\n",
    "    pass\n",
    "seq1 = [[1,2],[2,3]]\n",
    "seq2 = [[33,22],[12,1],[3,4]]\n",
    "seqs = check_merge(seq1,seq2)\n",
    "len(seqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "x = np.array([[1,2,1],[2,2,2]])\n",
    "y = max((x.shape[0],x.shape[1]))\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pathname = os.path.join(\"./\",\"imgs/\")\n",
    "print(pathname)\n",
    "files = os.listdir(pathname)\n",
    "for f in files:\n",
    "    if f.endswith(\".jpg\"):\n",
    "        print(f)\n",
    "# file_num = sum([os.path.isfile(\"./imgs/\"+f) for f in os.listdir(\"./imgs/*.jpg\")])\n",
    "# print(file_num)\n",
    "# print(\"./imgs/\".join(\"ss\"))\n",
    "# print(os.listdir(\"./imgs\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb1=[1,32,2,1]\n",
    "lb2=[\"pp\",\"xx\",\"lb22\",\"dd\"]\n",
    "for i,d in enumerate(lb2,0):\n",
    "    print(i,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch as tf\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "#python 实现二元二次回归 版本2 矩阵乘法\n",
    "#\n",
    "import numpy as np\n",
    "np.random.seed(10)\n",
    "\n",
    "w15=np.array([0.2,0.02,0.7,0.12, 0.1])\n",
    "X1 = np.random.randn(10000,1)+0.5\n",
    "X2 = np.random.randn(10000,1)+0.5\n",
    "X = np.hstack((X1**2,X2**2,X1,X2,np.ones_like(X1)))\n",
    "Y=np.sum(w15*X,axis=1).reshape(-1,1)\n",
    "\n",
    "\n",
    "lr = 0.0000001 #0.0000001\n",
    "epochs = 6000\n",
    "\n",
    "W15=np.array([0.9,0.72,0.03,0.002,0.92])\n",
    "for j in range(epochs):\n",
    "    Y_pred=np.sum(W15*X,axis=1).reshape(-1,1)\n",
    "    \n",
    "    #ydiff = (Y_pred-Y)/Y.shape[0]\n",
    "    ydiff = (Y_pred - Y)/(np.fabs(Y_pred-Y)+0.0000001)\n",
    "    loss = np.sum((Y_pred-Y)*(Y_pred-Y))/Y.shape[0]\n",
    "    W15 = W15 - np.array([lr,lr,lr,lr,lr])*np.sum(X*ydiff,axis=0)\n",
    "\n",
    "    if j%100==0: print(f\"({j}/{epochs}):loss:{loss}\")\n",
    "print(\"label w1..5:\",w15)\n",
    "print(\"pred W1..5\",W15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# calc_stack_act = {\"##\":-1,\"#(\":1, \"#)\":-1,\"#+\":1, \"#-\":1, \"#*\":1, \"#/\":1,\n",
    "#                   \"(#\":-1,\"((\":1, \"()\":0, \"(+\":1, \"(-\":1, \"(*\":1, \"(/\":1,\n",
    "#                   \")#\":-1,\")(\":-1,\"))\":-1,\")+\":1, \")-\":-1,\")*\":-1,\")/\":-1,\n",
    "#                   \"+#\":-1,\"+(\":1, \"+)\":0, \"++\":0, \"+-\":0, \"+*\":1, \"+/\":1,}\n",
    "def calc_value(exp):\n",
    "    try:\n",
    "        v = eval(exp)\n",
    "        print(\"Calc result:\",v)\n",
    "        return \"Result:\"+str(v)\n",
    "    except Exception as e:\n",
    "        print(\"Calc Error!:\",e)\n",
    "        return \"Calc Error!\"\n",
    "    \n",
    "calc_value(\"23*243-2/2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "time.time()/1000\n",
    "laobei=[0 for i in range(10)]\n",
    "\n",
    "\n",
    "for pp in range(100):\n",
    "    t1=time.time()\n",
    "    pp= 0\n",
    "    while pp<10000:\n",
    "        pp += 1\n",
    "        for s in laobei:\n",
    "            s += 1\n",
    "    t2=time.time()\n",
    "    print(\"tim:\",t2-t1)\n",
    "    time.sleep(1)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as tf\n",
    "import numpy as np\n",
    "tf.manual_seed(0)\n",
    "w15 = tf.tensor([1.2,2.02,-0.7,0.6,1.12, 1.1])\n",
    "X1 = tf.randn(10000,1)*10-2   #生成测试数据\n",
    "X2 = tf.randn(10000,1)*30-17   #tf.normal(0,1,size=(10000,1))+0.5 #tf.rand(10000,1)+0.5\n",
    "X = tf.hstack((X1**2,X2**2,X1*X2,X1,X2,tf.ones_like(X1)))\n",
    "\n",
    "Y = tf.sum(w15*X,dim=1).reshape(-1,1)\n",
    "print(\"tfnormal:\",Y.shape)\n",
    "\n",
    "\n",
    "lr = 0.1 #0.0000001\n",
    "\n",
    "epochs = 8000\n",
    "\n",
    "W15=tf.tensor([-1.9,0.72,2.03,0.3,0.002,0.92],requires_grad=True)\n",
    "lossfn = tf.nn.MSELoss()\n",
    "#optimizer = tf.optim.SGD([W15], lr=lr,momentum=0.9)\n",
    "optimizer = tf.optim.Adam([W15], lr=lr)\n",
    "\n",
    "for j in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    Y_pred=tf.sum(W15*X,dim=1).reshape(-1,1)# + tf.randn(10000,1)*10.0 - 5\n",
    "    #loss = tf.sum(Y_pred>Y) + tf.sum(Y_pred<Y)\n",
    "    #loss = tf.abs((Y_pred-Y).sum()* (Y_pred-Y).sum())\n",
    "    YY = Y+tf.rand(10000,1)*2-1\n",
    "    loss = tf.abs(Y_pred-YY).sum()**2# + 0.1*tf.sum(W15*W15)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if j%100==0: print(f\"({j}/{epochs}):loss:{loss}\")\n",
    "\n",
    "print(\"label w1..5:\",w15)\n",
    "print(\"pred W1..5\",W15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as tf\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "x = tf.randn(2,1,40,50).float()\n",
    "t = F.avg_pool2d(x,kernel_size=x.shape[-2:],stride=x.shape[-2:])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "int2binary = {}\n",
    "max_n = np.power(2,8)\n",
    "binary = np.unpackbits(np.array([range(max_n)], dtype = np.uint8).T,axis = 1)\n",
    "f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = (12,123)\n",
    "print(str(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "import torch.utils.data as data\n",
    "from torchvision.datasets.utils import download_url, check_integrity\n",
    "\n",
    "\n",
    "\n",
    "def download_voc12(url, root, filename, md5):\n",
    "    download_url(url, root, filename, md5)\n",
    "    with tarfile.open(os.path.join(root, filename), \"r\") as tar:\n",
    "        tar.extractall(path=root)\n",
    "\n",
    "def main():\n",
    "    url = 'http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar'\n",
    "    filename = 'VOCtrainval_11-May-2012.tar'\n",
    "    md5 = '6cd6e144f989b92b3379bac3b3de84fd'\n",
    "    download_voc12(url, './', filename, md5)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen():\n",
    "    import random\n",
    "    vx = 3\n",
    "    for i in range(30000):\n",
    "        if vx>1.0 or vx<-1.0: rnd = 0.2+random.random()\n",
    "        else: rnd = 2.0+2*random.random()\n",
    "        vx = vx *rnd\n",
    "        print(vx)\n",
    "\n",
    "gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtWidgets import * #QWidget, QSizePolicy, QMainWindow, QApplication\n",
    "from PyQt5.QtGui import *\n",
    "from PyQt5.QtCore import *\n",
    "import Ui_dlg_handnet\n",
    "class Dlg_main(QDialog, Ui_dlg_handnet.Ui_dlg_main):\n",
    "    def __init__(self, parent = None):\n",
    "        super(Dlg_main, self).__init__(parent)\n",
    "        self.setupUi(self)\n",
    "if __name__ == \"__main__\":\n",
    "    app = QApplication(sys.argv)\n",
    "    mainw = Dlg_main()\n",
    "    mainw.show()\n",
    "    sys.exit(app.exec_())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    " \n",
    "# 明确配置变量\n",
    "ip_port = ('192.168.0.131',1221)\n",
    "back_log = 5\n",
    "buffer_size = 1024\n",
    "# 创建一个TCP套接字\n",
    "ser = socket.socket(socket.AF_INET,socket.SOCK_STREAM)   # 套接字类型AF_INET, socket.SOCK_STREAM   tcp协议，基于流式的协议\n",
    "ser.setsockopt(socket.SOL_SOCKET,socket.SO_REUSEADDR,1)  # 对socket的配置重用ip和端口号\n",
    "# 绑定端口号\n",
    "ser.bind(ip_port)  #  写哪个ip就要运行在哪台机器上\n",
    "# 设置半连接池\n",
    "ser.listen(back_log)  # 最多可以连接多少个客户端\n",
    "while 1:\n",
    "    # 阻塞等待，创建连接\n",
    "    con,address = ser.accept()  # 在这个位置进行等待，监听端口号 \n",
    "    print(con,address)\n",
    "    while True:\n",
    "        try:\n",
    "            # 接受套接字的大小，怎么发就怎么收\n",
    "            msg = con.recv(buffer_size).decode('utf-8')\n",
    "            con.send(\"stnlcd ok\".encode('utf-8'))\n",
    "            if msg == '1':\n",
    "                # 断开连接\n",
    "                con.close()\n",
    "                print(\"disconnected!\")\n",
    "                break\n",
    "            print('服务器收到消息',msg)\n",
    "        except Exception as e:\n",
    "            break\n",
    "# 关闭服务器\n",
    "ser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "189d94fa0ea47d3e55cf3df04025e74e76faf3de3d79b55a94cc721dba6d4db5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
